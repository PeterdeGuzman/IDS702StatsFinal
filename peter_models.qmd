---
title: "peter_models"
format: html
author: "Peter de Guzman"
editor: visual
---

## 

# Loading Packages

```{r}
library(tidyverse)
library(ordinal)
library(car)
library(brant)
library(MASS)
```

# Loading data

```{r}
load("/Users/pdeguz01/Documents/git/Data/2020 CMPS/Output/2020cmps_clean.RData")
```

# Running chi-square tests

```{r}
# Create a summary table for all categorical variables
variables <- c("Q29", "Q271", "S2_RACE_PRIME", "S3", "S3B", "S5_AGE", "S13", "S14", "S7", "Q21", "S2_M", "Q627", "Q628", "Q629R1", "Religion", "educ", "sex_orientation", "rural", "white", "race_recoded", "age_recoded")


# Chi-square tests for each variable
chi_square_results <- lapply(variables, function(var) {
  chisq.test(table(dataset_clean[[var]], dataset_clean$Q29))
})

# Print chi-square results
names(chi_square_results) <- variables
print(chi_square_results)
```

| Variable | Chi-Sq Test Statistic | Degrees of Freedom (df) | p-value |
|----|----|----|----|
| Q271 | 291.49 | 12 | \< 2.2e-16 |
| S2_RACE_PRIME | 291.12 | 21 | \< 2.2e-16 |
| S3 | 101.7 | 15 | 6.196e-15 |
| S3B | 296.35 | 9 | \< 2.2e-16 |
| S5_AGE | NaN | 18 | NA |
| S13 | 710.69 | 18 | \< 2.2e-16 |
| S14 | 196.79 | 12 | \< 2.2e-16 |
| S7 | 148.62 | 6 | \< 2.2e-16 |
| Q21 | 1284.1 | 9 | \< 2.2e-16 |
| S2_M | 6.0327 | 3 | 0.11 |
| Q627 | 246.82 | 3 | \< 2.2e-16 |
| Q628 | 9.0318 | 6 | 0.1718 |
| Q629R1 | 6.9533 | 3 | 0.0734 |
| Religion | 562.39 | 45 | \< 2.2e-16 |
| educ | 608.65 | 6 | \< 2.2e-16 |
| sex_orientation | 55.679 | 6 | 3.379e-10 |
| rural/urban&suburban | 83.719 | 3 | \< 2.2e-16 |
| white/non-white | 75.137 | 3 | 3.386e-16 |
| race_recoded | 276.36 | 18 | \< 2.2e-16 |
| age_recoded | 396.97 | 15 | \< 2.2e-16 |

## Takeaways from Chi-Square Test

Our outcome variable is Q29 (interest in politics).

There appears to be a significant relationship between the following variables and Q29 (interest in politics):

-   Age (Recoded)

-   Race (Recoded)

-   Gender

-   White or Non-White status

-   Rural or Urban & Suburban status

-   Sexual Orientation

-   Religion

-   Educational Attainment

-   Having experienced prior discrimination (Q627)

-   Political Party ID

-   Nativity (born in US or other)

# Fitting OLR Model Using polr()

```{r}
library(MASS) # package for model
library(caret) # package for confusion matrix

dataset_clean$Q29_reordered  <- factor(dataset_clean$Q29,
                            levels = c("(4) Not at all interested in politics",
                                     "(3) Not that interested in politics",
                                     "(2) Somewhat interested",
                                     "(1) Very interested in politics"))


dataset_clean$Q271_reordered <- factor(dataset_clean$Q271,
                            levels = c("(5) Not at all important",
                                     "(4) Slightly important",
                                     "(3) Moderately important",
                                     "(2) Very important",
                                     "(1) Extremely important"))

ord_mod <- polr(Q29 ~ Q271_reordered + race_recoded +
                  age_recoded +
            educ +  # Educational Attainment
            S3B + # Gender
            Q21, # Party affiliation
          data = dataset_clean, Hess=TRUE)

summary(ord_mod)


pvals <- pnorm(-abs(summary(ord_mod)$coef[,"t value"]))*2
ctable <- cbind(summary(ord_mod)$coef,pvals)

ctable

(exp_coefs <- exp(cbind(OR=coef(ord_mod),confint(ord_mod))))

head(ord_mod$fitted.values)
head(predict(ord_mod))

confusionMatrix(predict(ord_mod), dataset_clean$Q29, mode="everything")

```

```{r}
# generate predictions for the ordinal model

new_dataset <- data.frame

predict(ord_mod, new_dataset)
```

# Fitting OLR with interaction terms



```{r}
library(MASS) # package for model
library(caret) # package for confusion matrix

# dataset_clean$Q271_reordered <- factor(dataset_clean$Q271,
#                             levels = c("(5) Not at all important",
#                                      "(4) Slightly important",
#                                      "(3) Moderately important",
#                                      "(2) Very important",
#                                      "(1) Extremely important"))

ord_mod_interactions <- polr(Q29 ~ Q271_reordered + race_recoded +
                  age_recoded +
            educ +  # Educational Attainment
            S3B + # Gender
            Q21, # Party affiliation
          data = dataset_clean, Hess=TRUE)

summary(ord_mod_interactions)


pvals_interact <- pnorm(-abs(summary(ord_mod_interactions)$coef[,"t value"]))*2
ctable_interact <- cbind(summary(ord_mod_interactions)$coef,pvals)

ctable_interact

(exp_coefs_interact <- exp(cbind(OR=coef(ord_mod_interactions),confint(ord_mod_interactions))))

head(ord_mod_interactions$fitted.values)
head(predict(ord_mod_interactions))

confusionMatrix(predict(ord_mod_interactions), dataset_clean$Q29, mode="everything")

```

```{r}
# generate predictions for the ordinal model with interactions

new_dataset <- data.frame

predict(ord_mod, new_dataset)
```


# Fitting MLR Model

```{r}

# Load packages
library(nnet)  # for multinomial logistic regression
library(tidyverse)
library(car)
library(effects)


# ensure outcome variable is a factor but not ordered
dataset_clean$Q29_unordered <- factor(dataset_clean$Q29, ordered = FALSE)
dataset_clean$Q271_simple <- as.numeric(dataset_clean$Q271)

# Fit multinomial model
m_mult <- multinom(Q29_unordered ~ Q271 + race_recoded + age_recoded +
            # rural + # Rural or Urban/Suburban
            # sex_orientation + # Sexual Orientation
            educ + # Educational Attainment
            S3B + # Gender
            # S7 + # Nativity
            Q21, # Party affiliation
          data = dataset_clean)



# Calculate predicted probabilities of marginal effects
# Create sequence of Q271_simple values
x_vals <- seq(min(dataset_clean$Q271_simple), max(dataset_clean$Q271_simple), length.out = 100)

# Function to calculate average predicted probabilities
get_avg_probs <- function(model, newdata, var_name) {
    preds <- predict(model, newdata = newdata, type = "probs")
    colMeans(preds)
}

# Calculate marginal effects by race
races <- unique(dataset_clean$race_recoded)
marg_effects <- list()

for(race in races) {
    probs <- matrix(0, nrow = length(x_vals), ncol = length(levels(dataset_clean$Q29_unordered)))
    for(i in seq_along(x_vals)) {
        temp_data <- dataset_clean
        temp_data$Q271_simple <- x_vals[i]
        temp_data$race_major <- race
        probs[i,] <- get_avg_probs(m_mult, temp_data, "Q271_simple")
    }
    marg_effects[[race]] <- data.frame(
        x = x_vals,
        race = race,
        prob1 = probs[,1],
        prob2 = probs[,2],
        prob3 = probs[,3],
        prob4 = probs[,4]
    )
}

# Combine all marginal effects
marg_effects_df <- bind_rows(marg_effects)

# Create plots for marginal effects
# Reshape data for plotting
marg_effects_long <- marg_effects_df %>%
    pivot_longer(cols = starts_with("prob"),
                names_to = "outcome",
                values_to = "probability") %>%
    mutate(outcome = factor(outcome,
                          levels = paste0("prob", 1:4),
                          labels = levels(dataset_clean$Q29_unordered)))

# Plot marginal effects
p1 <- ggplot(marg_effects_long, 
             aes(x = x, y = probability, color = outcome)) +
    geom_line() +
    facet_wrap(~race) +
    theme_minimal() +
    labs(title = "Marginal Effects of Racial Identity Importance by Race",
         x = "Importance of Racial Identity",
         y = "Predicted Probability",
         color = "Political Interest Level") +
    theme(legend.position = "bottom")
print(p1)

# Model fit statistics and comparisons
print("Model summaries:")
print(summary(m_mult))

# Calculate McFadden's R-squared
null_model <- multinom(Q29_unordered ~ 1, data = dataset_clean)
mcfadden_r2 <- 1 - logLik(m_mult)/logLik(null_model)

print("McFadden's R-squared:")
print(mcfadden_r2)

# Classification accuracy
pred_class <- predict(m_mult)
conf_matrix <- table(pred_class, dataset_clean$Q29_unordered)
accuracy <- sum(diag(conf_matrix))/sum(conf_matrix)

print("Classification accuracy:")
print(accuracy)
print("Confusion Matrix:")
print(conf_matrix)

# Print AIC
print(AIC(m_mult))

# Calculate predicted probabilities
pred_data <- expand.grid(
    Q271 = unique(dataset_clean$Q271),
    age_recoded = unique(dataset_clean$age_recoded),
    race_recoded = unique(dataset_clean$race_recoded),
    educ = unique(dataset_clean$educ),
    S3B = unique(dataset_clean$S3B),
    Q21 = unique(dataset_clean$Q21)
)

# Get predictions
preds <- predict(m_mult, newdata = pred_data, type = "probs")
pred_data <- cbind(pred_data, as.data.frame(preds))

# Create separate plots for each outcome level
pred_long <- pred_data %>%
    pivot_longer(cols = starts_with("("),
                names_to = "interest_level",
                values_to = "probability")


# Plot for each outcome level
p2 <- ggplot(pred_long, 
             aes(x = Q271, y = probability, color = race_recoded)) +
    geom_line() +
    facet_wrap(~interest_level) +
    theme_minimal() +
    labs(title = "Predicted Probabilities by Outcome Level",
         x = "Importance of Racial Identity",
         y = "Probability",
         color = "Race/Ethnicity") +
    theme(legend.position = "bottom")
print(p2)


```

## Interpretation


# Fitting OLR Model Using clm() (Following Jennifer's method)

```{r}
dataset_clean$Q271_simple <- as.numeric(dataset_clean$Q271)
# dataset_clean$Q271 <- factor(dataset_clean$Q271,
#                             levels = c("(5) Not at all important",
#                                      "(4) Slightly important",
#                                      "(3) Moderately important",
#                                      "(2) Very important",
#                                      "(1) Extremely important"),
#                             ordered = TRUE)

m1 <- clm(Q29 ~ Q271 + race_recoded + age_recoded +
            rural + # Rural or Urban/Suburban
            sex_orientation + # Sexual Orientation
            Religion + 
            educ + # Educational Attainment
            S3B + # Gender
            S7 + # Nativity
            Q21, # Party affiliation
          data = dataset_clean)

summary(m1)

# Check for multicollinearity using a linear approximation
vif_m1 <- vif(lm(as.numeric(Q29) ~ Q271 + race_recoded + age_recoded +
            rural + # Rural or Urban/Suburban
            sex_orientation + # Sexual Orientation
            Religion + 
            educ + # Educational Attainment
            S3B + # Gender
            S7 + # Nativity
            Q21, # Party affiliation
          data = dataset_clean))

print("Variance Inflation Factors:")
print(vif_m1)

# Test proportional odds assumption
print("Testing proportional odds assumption:")
test1 <- nominal_test(m1)
print("Nominal test for Model 1:")
print(test1)

# Alternative diagnostic approach using linear approximation
lm_approx <- lm(as.numeric(Q29) ~ Q271 + race_recoded + age_recoded +
            rural + # Rural or Urban/Suburban
            sex_orientation + # Sexual Orientation
            Religion + 
            educ + # Educational Attainment
            S3B + # Gender
            S7 + # Nativity
            Q21, # Party affiliation
          data = dataset_clean)
diagnostics_df <- data.frame(
  fitted = fitted(lm_approx),
  residuals = residuals(lm_approx),
  index = 1:nrow(dataset_clean)
)

# Plot residuals vs fitted values using linear approximation
p1 <- ggplot(diagnostics_df, aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = "loess") +
  theme_minimal() +
  labs(title = "Residuals vs Fitted Values (Linear Approximation)",
       x = "Fitted Values",
       y = "Residuals")
print(p1)

# Calculate and plot Cook's distance
cooks_d <- cooks.distance(lm_approx)
influence_df <- data.frame(
  index = 1:length(cooks_d),
  cooks_distance = cooks_d
)

p2 <- ggplot(influence_df, aes(x = index, y = cooks_distance)) +
  geom_point() +
  geom_hline(yintercept = 4/nrow(dataset_clean), color = "red", linetype = "dashed") +
  theme_minimal() +
  labs(title = "Cook's Distance Plot",
       x = "Observation Number",
       y = "Cook's Distance")
print(p2)

# Count influential observations
influential_obs <- which(cooks_d > 4/nrow(dataset_clean))
print("Number of influential observations:")
print(length(influential_obs))



# Create prediction visualization
pred_data <- expand.grid(
  Q271 = levels(dataset_clean$Q271),
  race_recoded = levels(dataset_clean$race_recoded), 
  age_recoded = levels(dataset_clean$age_recoded),
  rural = levels(dataset_clean$rural),
  sex_orientation = levels(dataset_clean$sex_orientation),
  Religion = levels(dataset_clean$Religion),
  educ = levels(dataset_clean$educ),
  S3B = levels(dataset_clean$S3B),
  S7 = levels(dataset_clean$S7),
  Q21 = levels(dataset_clean$Q21)
)

# Get predicted probabilities
preds <- predict(m1, newdata = pred_data, type = "prob")
# Convert predictions to numeric scores (weighted average)
pred_data$predicted_score <- apply(preds$fit, 1, function(x) sum(x * 1:4))

# Create prediction plot
p3 <- ggplot(pred_data, aes(x = Q271, y = predicted_score, color = race_recoded)) +
  geom_point() +
  geom_line(aes(group = race_recoded)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Predicted Political Interest by Racial Identity Importance and Race",
       x = "Importance of Racial Identity",
       y = "Predicted Political Interest Level (1-4)",
       color = "Race/Ethnicity")
print(p3)

# Print the coefficients table
print("Coefficients for Model 1:")
coef_table <- summary(m1)$coefficients
print(coef_table)

# Calculate and print odds ratios for the coefficients
odds_ratios <- exp(coef_table[, "Estimate"])
print("Odds Ratios:")
print(odds_ratios)


```

## Interpretation

1.  Model Fit:
    1.  AIC is 42342.54
    2.  Log-likelihood is -21125.27
2.  Proportional Odds Assumption

-   The nominal test for Model 1 shows significant violations (p \< 0.05 for all predictor variables except for Religion)

-   This suggests the effect of racial identity importance varies across different levels of political interest

1.  Multicollinearity

-   Interpretation of VIF values

1.  Residuals and Model Diagnostics

-   The residuals plot shows:

    -   A relatively flat line around zero

    -   Straight downward slope patterns in the residuals

1.  Influential Points:
    -   There are 804 influential observations.

    -   Cook's distance plot shows multiple observations above the threshold.

    -   Given the large sample size (17,545), this number of influential points is not extremely concerning.
2.  Key Findings from Model 1:
    1.  The different levels of racial identity importance are all significant
    2.  There are differences among racial/ethnic groups
3.  Predicted Relationships (from plot)
    1.  

